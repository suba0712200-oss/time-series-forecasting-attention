{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMskEmVF6GJUpK88dQT2p1L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suba0712200-oss/time-series-forecasting-attention/blob/main/Implementing_Variational_Autoencoders_for_Anomaly_Detection_on_Synthetic_High_Dimensional_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1w3xmfNq38n6"
      },
      "outputs": [],
      "source": [
        "# 1. Import Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Synthetic Dataset Generation\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Normal data\n",
        "X_normal, _ = make_blobs(\n",
        "    n_samples=9800,\n",
        "    n_features=50,\n",
        "    centers=1,\n",
        "    cluster_std=1.0\n",
        ")\n",
        "\n",
        "# Anomalies\n",
        "X_anomaly, _ = make_blobs(\n",
        "    n_samples=200,\n",
        "    n_features=50,\n",
        "    centers=1,\n",
        "    cluster_std=5.0\n",
        ")\n",
        "\n",
        "X = np.vstack([X_normal, X_anomaly])\n",
        "y = np.hstack([np.zeros(9800), np.ones(200)])\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.int64)\n"
      ],
      "metadata": {
        "id": "DQQKUbdh4JcD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. DataLoader\n",
        "\n",
        "dataset = TensorDataset(X_tensor)\n",
        "loader = DataLoader(dataset, batch_size=128, shuffle=True)\n"
      ],
      "metadata": {
        "id": "Yl4X6CWW4PLj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. VAE Model Architecture\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.mu = nn.Linear(64, latent_dim)\n",
        "        self.log_var = nn.Linear(64, latent_dim)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_dim)\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(0.5 * log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        mu = self.mu(encoded)\n",
        "        log_var = self.log_var(encoded)\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "        reconstructed = self.decoder(z)\n",
        "        return reconstructed, mu, log_var\n"
      ],
      "metadata": {
        "id": "rCAUCcvY4SSy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Loss Function (ELBO)\n",
        "\n",
        "def vae_loss(recon_x, x, mu, log_var):\n",
        "    recon_loss = nn.MSELoss(reduction='sum')(recon_x, x)\n",
        "    kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "    return recon_loss + kl_loss\n"
      ],
      "metadata": {
        "id": "TT8yJfMv4V9P"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Model Training\n",
        "\n",
        "def train_vae(latent_dim, epochs=20):\n",
        "    model = VAE(input_dim=50, latent_dim=latent_dim)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch in loader:\n",
        "            data = batch[0]\n",
        "            optimizer.zero_grad()\n",
        "            recon, mu, log_var = model(data)\n",
        "            loss = vae_loss(recon, data, mu, log_var)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.2f}\")\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "svRce5Zq4ZX9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Anomaly Score Calculation\n",
        "\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        recon, mu, log_var = model(X_tensor)\n",
        "        reconstruction_error = torch.mean((X_tensor - recon) ** 2, dim=1)\n",
        "        return reconstruction_error.numpy()\n"
      ],
      "metadata": {
        "id": "aK8W7Gnw4ZRn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. AUC-ROC Evaluation\n",
        "\n",
        "latent_dims = [5, 10, 20]\n",
        "auc_scores = {}\n",
        "\n",
        "for ld in latent_dims:\n",
        "    print(f\"\\nTraining VAE with latent dimension = {ld}\")\n",
        "    model = train_vae(ld)\n",
        "    scores = evaluate(model)\n",
        "    auc = roc_auc_score(y, scores)\n",
        "    auc_scores[ld] = auc\n",
        "    print(f\"AUC-ROC for latent dim {ld}: {auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hvla9O8h4enZ",
        "outputId": "3d5c0af3-548a-44a1-db1e-0e07bb34714f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training VAE with latent dimension = 5\n",
            "Epoch 1, Loss: 415000.89\n",
            "Epoch 2, Loss: 354424.99\n",
            "Epoch 3, Loss: 351043.66\n",
            "Epoch 4, Loss: 349251.65\n",
            "Epoch 5, Loss: 348662.45\n",
            "Epoch 6, Loss: 348804.04\n",
            "Epoch 7, Loss: 346669.26\n",
            "Epoch 8, Loss: 346186.73\n",
            "Epoch 9, Loss: 345744.48\n",
            "Epoch 10, Loss: 344725.47\n",
            "Epoch 11, Loss: 342948.11\n",
            "Epoch 12, Loss: 341884.76\n",
            "Epoch 13, Loss: 341713.31\n",
            "Epoch 14, Loss: 340270.94\n",
            "Epoch 15, Loss: 339694.47\n",
            "Epoch 16, Loss: 339078.85\n",
            "Epoch 17, Loss: 338786.58\n",
            "Epoch 18, Loss: 338511.79\n",
            "Epoch 19, Loss: 337761.15\n",
            "Epoch 20, Loss: 337274.19\n",
            "AUC-ROC for latent dim 5: 1.0000\n",
            "\n",
            "Training VAE with latent dimension = 10\n",
            "Epoch 1, Loss: 425081.31\n",
            "Epoch 2, Loss: 356425.61\n",
            "Epoch 3, Loss: 352114.73\n",
            "Epoch 4, Loss: 350447.93\n",
            "Epoch 5, Loss: 348859.42\n",
            "Epoch 6, Loss: 349395.42\n",
            "Epoch 7, Loss: 348846.52\n",
            "Epoch 8, Loss: 347732.18\n",
            "Epoch 9, Loss: 348096.87\n",
            "Epoch 10, Loss: 347612.59\n",
            "Epoch 11, Loss: 347763.23\n",
            "Epoch 12, Loss: 346834.04\n",
            "Epoch 13, Loss: 346721.28\n",
            "Epoch 14, Loss: 347045.69\n",
            "Epoch 15, Loss: 346598.56\n",
            "Epoch 16, Loss: 346400.42\n",
            "Epoch 17, Loss: 346476.36\n",
            "Epoch 18, Loss: 346204.27\n",
            "Epoch 19, Loss: 347209.70\n",
            "Epoch 20, Loss: 345085.17\n",
            "AUC-ROC for latent dim 10: 1.0000\n",
            "\n",
            "Training VAE with latent dimension = 20\n",
            "Epoch 1, Loss: 416788.63\n",
            "Epoch 2, Loss: 355644.42\n",
            "Epoch 3, Loss: 352027.78\n",
            "Epoch 4, Loss: 351922.92\n",
            "Epoch 5, Loss: 350321.38\n",
            "Epoch 6, Loss: 351618.99\n",
            "Epoch 7, Loss: 349409.99\n",
            "Epoch 8, Loss: 348662.26\n",
            "Epoch 9, Loss: 348289.71\n",
            "Epoch 10, Loss: 347424.55\n",
            "Epoch 11, Loss: 348544.78\n",
            "Epoch 12, Loss: 348127.30\n",
            "Epoch 13, Loss: 347025.79\n",
            "Epoch 14, Loss: 347306.39\n",
            "Epoch 15, Loss: 346815.59\n",
            "Epoch 16, Loss: 347137.97\n",
            "Epoch 17, Loss: 346677.85\n",
            "Epoch 18, Loss: 345939.80\n",
            "Epoch 19, Loss: 345338.58\n",
            "Epoch 20, Loss: 344621.55\n",
            "AUC-ROC for latent dim 20: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Results & Analysis\n",
        "\n",
        "final_scores = scores.tolist()\n",
        "print(\",\".join(map(str, final_scores[:200])))  # preview\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVOR150K4iwU",
        "outputId": "d33b6372-b730-4f91-a636-b058acaeac52"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5040157437324524,0.39200425148010254,0.35280197858810425,0.47212550044059753,0.3792875409126282,0.5617756843566895,0.5473516583442688,0.57037353515625,0.49684181809425354,0.5089572668075562,0.5743149518966675,0.26335370540618896,0.3197672367095947,0.41882583498954773,0.512352705001831,0.30921050906181335,0.3356395363807678,0.4801691770553589,0.4136938452720642,0.44558510184288025,0.4841136634349823,0.5334721207618713,0.4089968502521515,0.7923189401626587,0.5038527846336365,0.38222819566726685,0.3677014112472534,0.42980507016181946,0.330659955739975,0.5835064053535461,0.45232436060905457,0.4643898010253906,0.6415038108825684,0.4338971674442291,0.5476923584938049,0.3894232213497162,0.4097849130630493,0.5171718001365662,0.3540676236152649,0.5395333766937256,0.6163232326507568,0.4045148491859436,0.2983090877532959,0.447322815656662,0.4261983633041382,0.3382141888141632,0.5015267729759216,0.470851868391037,0.5047181844711304,0.5178002715110779,0.4025498330593109,0.3747885227203369,0.4293714463710785,0.34155380725860596,0.48292937874794006,0.5485690236091614,0.31620776653289795,0.5057801008224487,0.43352240324020386,0.6674801111221313,0.5798949599266052,0.415535569190979,0.5903111696243286,0.45620518922805786,0.4094949960708618,0.44500237703323364,0.6623967885971069,0.48227742314338684,0.3312959671020508,0.35453784465789795,0.38775694370269775,0.36939263343811035,0.5105559825897217,0.2426198422908783,0.4064714312553406,0.6304962038993835,0.5180423259735107,0.4134661853313446,0.4291958212852478,0.614897608757019,0.4624795615673065,0.5429070591926575,0.43628519773483276,0.4390984773635864,0.49423354864120483,0.38990938663482666,0.46762898564338684,0.6178695559501648,0.47964733839035034,0.3060246407985687,0.524711012840271,0.4134291410446167,0.3275415301322937,0.5392424464225769,0.49368971586227417,0.38131943345069885,0.4189409017562866,0.34056952595710754,0.5470020174980164,0.3930840790271759,0.5094426870346069,0.45906051993370056,0.46321552991867065,0.5792699456214905,0.3285231292247772,0.5305211544036865,0.41480880975723267,0.29528307914733887,0.5162021517753601,0.49551668763160706,0.4533296823501587,0.571601152420044,0.4520379900932312,0.5738773345947266,0.516565203666687,0.4306253492832184,0.4147792458534241,0.35798290371894836,0.5207681059837341,0.5517174005508423,0.5602837204933167,0.33272016048431396,0.39585044980049133,0.4374178349971771,0.311743825674057,0.18298564851284027,0.5150240063667297,0.48628053069114685,0.31308794021606445,0.4915895462036133,0.4764972925186157,0.3892500698566437,0.46786749362945557,0.6424045562744141,0.47043564915657043,0.435528039932251,0.49471932649612427,0.29882004857063293,0.39167797565460205,0.39099326729774475,0.4376114010810852,0.40027663111686707,0.4426882863044739,0.4607909023761749,0.42176228761672974,0.49418753385543823,0.517212450504303,0.42680180072784424,0.3346158564090729,0.40641799569129944,0.5634713172912598,0.5333360433578491,0.3847120404243469,0.528964638710022,0.4522441029548645,0.4781206548213959,0.49141642451286316,0.4588712453842163,0.4498835802078247,0.4706517457962036,0.40616852045059204,0.4135449528694153,0.7690231204032898,0.44641467928886414,0.45832377672195435,0.5566290020942688,0.568486213684082,0.5192328095436096,0.4057809114456177,0.4149080216884613,0.2940250039100647,0.29117804765701294,0.5046605467796326,0.47626954317092896,0.4619826376438141,0.4285353422164917,0.44977620244026184,0.7099657654762268,0.4217914640903473,0.38308385014533997,0.4249056279659271,0.346169114112854,0.26806536316871643,0.4061260223388672,0.5291640758514404,0.5435354113578796,0.4527662396430969,0.2909173369407654,0.507819652557373,0.5983846187591553,0.40691080689430237,0.2796317934989929,0.3414069414138794,0.41316795349121094,0.46710681915283203,0.47730863094329834,0.551781415939331,0.3584488332271576,0.4352279603481293,0.4001130759716034\n"
          ]
        }
      ]
    }
  ]
}